{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee7428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from helper_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d6fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipdata = get_zipdata()\n",
    "zipdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a640fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zipdata = zipdata.loc[zipdata.Population!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633a7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipdata.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b2e90f",
   "metadata": {},
   "source": [
    "Check Some correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbb938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr1 = zipdata.iloc[:,0:14].corr()\n",
    "corr2 = zipdata.iloc[:,14:].corr()\n",
    "\n",
    "mask1 = np.triu(np.ones_like(corr1, dtype=bool)) # Hide upper redundant heatmap\n",
    "mask2 = np.triu(np.ones_like(corr2, dtype=bool)) # Hide upper redundant heatmap\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "sns.heatmap(corr1, mask=mask1, ax=ax[0], annot=False, cmap='mako_r')\n",
    "sns.heatmap(corr2, mask=mask2, ax=ax[1], annot=False, cmap='mako_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e291c5c",
   "metadata": {},
   "source": [
    "Create Population Ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7131599",
   "metadata": {},
   "source": [
    "### üéöÔ∏è Scale data before clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a27e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "# REMOVE AverageHouseValue\n",
    "to_use = ['Population', 'HouseholdsPerZipCode', 'Blacks_ratio', 'Hispanics_ratio', \n",
    "          'Asians_ratio', 'Indians_ratio', 'Others_ratio', 'Male_ratio',                # Population\n",
    "          'IncomePerHousehold', 'NumberOfBusinesses','UE_rate', 'BEA_percap_income',    # Econ\n",
    "          'over_65_ratio','MedianAge',                                                  # Age\n",
    "          'HPI', 'Demand_score','Supply_score', 'listviews_vs_US', 'med_days_on_mkt', 'nielson_rank', # FRED\n",
    "         ]\n",
    "\n",
    "data_scaled = pd.DataFrame(mms.fit_transform(zipdata[to_use].values), \n",
    "                           columns=zipdata[to_use].columns, \n",
    "                           index=zipdata[to_use].index)\n",
    "# data_scaled = pd.DataFrame(mms.fit_transform(zipdata.drop(columns=['AverageHouseValue','school_rating']).values), \n",
    "#                            columns=zipdata.drop(columns=['AverageHouseValue','school_rating']).columns, \n",
    "#                            index=zipdata.drop(columns=['AverageHouseValue','school_rating']).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f6cbaf",
   "metadata": {},
   "source": [
    "### K-means Clustering of ZipCode data to produce desirability Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defadff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans()\n",
    "inertias = {}\n",
    "for n in range(1,15):\n",
    "    kmeans.set_params(n_clusters=n)\n",
    "    kmeans.fit(data_scaled[['HPI', 'Demand_score','Supply_score', 'listviews_vs_US', 'med_days_on_mkt', 'nielson_rank']])\n",
    "    inertias[n] = kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c6e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(inertias.keys(),inertias.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f5fecb",
   "metadata": {},
   "source": [
    "#### Try X Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e625a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.set_params(n_clusters=5)\n",
    "kmeans.fit(data_scaled[['HPI', 'Demand_score','Supply_score', 'listviews_vs_US', 'med_days_on_mkt', 'nielson_rank']])\n",
    "zipdata['fred_cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fbfd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipdata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3e421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zipdata.groupby('cluster').agg('count')['Population'])\n",
    "zipdata.groupby('cluster').agg('mean')[['AverageHouseValue','Population','over_65_ratio',\n",
    "                                       'IncomePerHousehold','school_rating','Hosp_count',\n",
    "                                       'HPI','UE_rate','Zillow_HVF','NumberOfBusinesses']].round(2).sort_values(by='AverageHouseValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f0a82d",
   "metadata": {},
   "source": [
    "## üé∞ Model with Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeef36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = get_redfin_csv()\n",
    "print(RF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0eabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF.Detached.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec90ea7c",
   "metadata": {},
   "source": [
    "#### Merge cluster into House data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5b0309",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'shape before merge: {RF.shape}')\n",
    "RF = RF.merge(zipdata, how = 'left', left_on = 'zip', right_index=True)\n",
    "RF.cluster = RF.cluster.astype('object')\n",
    "print(f'shape after merge: {RF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6733d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=RF.cluster, y=np.log10(RF.PRICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb16b3cb",
   "metadata": {},
   "source": [
    "## Try Linear Model and CatBoostüê±\n",
    "* Label Encode **Prop_Type & zip**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e89861a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "Linear Model train R2: 0.7564106237398096\n",
      "Linear Model test R2: 0.6940527804434616\n",
      "CatBoost train R2: 0.8662031744466588\n",
      "CatBoost Model test R2: 0.8394565184933434\n"
     ]
    }
   ],
   "source": [
    "# target_feats = ['Prop_Type','BEDS','BATHS','SF','Lot_Size','YearBuilt','zip']\n",
    "# target_feats = ['Prop_Type','BEDS','BATHS','SF','Lot_Size','YearBuilt','zip','cluster']\n",
    "# target_feats = ['Prop_Type','BEDS','BATHS','SF','Lot_Size','YearBuilt','zip','cluster','school_rating']\n",
    "target_feats = ['Prop_Type','BEDS','BATHS','SF','Lot_Size','YearBuilt','zip',\n",
    "               'pop_cluster', 'econ_cluster', 'age_cluster', 'fred_cluster','school_rating','Zillow_HVF']\n",
    "# target_feats = ['Prop_Type', 'BEDS', 'BATHS', 'SF', 'Lot_Size', 'YearBuilt', 'zip',\n",
    "#         'Population', 'HouseholdsPerZipCode', 'MedianAge', 'NumberOfBusinesses', \n",
    "#         'over_65_ratio', 'school_rating', 'Hosp_count', 'HPI', 'Demand_score', \n",
    "#         'Supply_score', 'listviews_vs_US', 'med_days_on_mkt', 'nielson_rank', \n",
    "#         'UE_rate', 'Zillow_HVF', 'BEA_percap_income', 'Blacks_ratio', \n",
    "#         'Hispanics_ratio', 'Asians_ratio', 'Indians_ratio', 'Others_ratio', \n",
    "#         'Male_ratio']\n",
    "\n",
    "lm = LinearRegression()\n",
    "cat = CatBoostRegressor(verbose=False)\n",
    "\n",
    "LM_train_R2 = []\n",
    "LM_test_R2 = []\n",
    "\n",
    "CAT_train_R2 = []\n",
    "CAT_test_R2 = []\n",
    "\n",
    "for i in range(5):\n",
    "    X_train_dum, X_test_dum, X_train_le, X_test_le, y_train, y_test = get_train_test(RF,target_feats)\n",
    "    lm.fit(X_train_dum, y_train)\n",
    "    LM_train_R2.append(lm.score(X_train_dum, y_train))\n",
    "    LM_test_R2.append(lm.score(X_test_dum, y_test))\n",
    "   \n",
    "    cat.fit(X_train_le, y_train)\n",
    "    CAT_train_R2.append(cat.score(X_train_le, y_train))\n",
    "    CAT_test_R2.append(cat.score(X_test_le, y_test))\n",
    "    print(i+1)\n",
    "\n",
    "print(f'Linear Model train R2: {np.average(LM_train_R2)}')\n",
    "print(f'Linear Model test R2: {np.average(LM_test_R2)}')\n",
    "print(f'CatBoost train R2: {np.average(CAT_train_R2)}')\n",
    "print(f'CatBoost Model test R2: {np.average(CAT_test_R2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13946b1",
   "metadata": {},
   "source": [
    "## üèïÔ∏è Try RandomForest and parameter tuning... manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7349739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "randoforest = RandomForestRegressor(n_jobs=-1)\n",
    "randoforest.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c7061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feats = ['Prop_Type','BEDS','BATHS','SF','Lot_Size','YearBuilt','zip']\n",
    "\n",
    "FST_train_R2 = []\n",
    "FST_test_R2 = []\n",
    "\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = get_train_test_LE(RF,target_feats)\n",
    "    randoforest.fit(X_train, y_train)\n",
    "    FST_train_R2.append(randoforest.score(X_train, y_train))\n",
    "    FST_test_R2.append(randoforest.score(X_test, y_test))\n",
    "    print(i+1)\n",
    "\n",
    "print(f'RandForest train R2: {np.average(FST_train_R2)}')\n",
    "print(f'RandForest test R2: {np.average(FST_test_R2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bdf969",
   "metadata": {},
   "outputs": [],
   "source": [
    "randoforest.set_params(max_depth=5,n_estimators=50)\n",
    "\n",
    "target_feats = ['Prop_Type','BEDS','BATHS','SF','Lot_Size','YearBuilt','zip']\n",
    "\n",
    "FST_train_R2 = []\n",
    "FST_test_R2 = []\n",
    "\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = get_train_test_LE(RF,target_feats)\n",
    "    randoforest.fit(X_train, y_train)\n",
    "    FST_train_R2.append(randoforest.score(X_train, y_train))\n",
    "    FST_test_R2.append(randoforest.score(X_test, y_test))\n",
    "    print(i+1)\n",
    "\n",
    "print(f'RandForest train R2: {np.average(FST_train_R2)}')\n",
    "print(f'RandForest test R2: {np.average(FST_test_R2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7745af",
   "metadata": {},
   "outputs": [],
   "source": [
    "randoforest.set_params(max_depth=8,n_estimators=50)\n",
    "\n",
    "target_feats = ['Prop_Type','BEDS','BATHS','SF','Lot_Size','YearBuilt','zip']\n",
    "\n",
    "FST_train_R2 = []\n",
    "FST_test_R2 = []\n",
    "\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = get_train_test_LE(RF,target_feats)\n",
    "    randoforest.fit(X_train, y_train)\n",
    "    FST_train_R2.append(randoforest.score(X_train, y_train))\n",
    "    FST_test_R2.append(randoforest.score(X_test, y_test))\n",
    "    print(i+1)\n",
    "\n",
    "print(f'RandForest train R2: {np.average(FST_train_R2)}')\n",
    "print(f'RandForest test R2: {np.average(FST_test_R2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16681094",
   "metadata": {},
   "outputs": [],
   "source": [
    "randoforest.set_params(max_depth=25, min_samples_leaf=10, n_estimators=50)\n",
    "\n",
    "target_feats = ['Prop_Type','BEDS','BATHS','SF','Lot_Size','YearBuilt','zip']\n",
    "\n",
    "FST_train_R2 = []\n",
    "FST_test_R2 = []\n",
    "\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = get_train_test_LE(RF,target_feats)\n",
    "    randoforest.fit(X_train, y_train)\n",
    "    FST_train_R2.append(randoforest.score(X_train, y_train))\n",
    "    FST_test_R2.append(randoforest.score(X_test, y_test))\n",
    "    print(i+1)\n",
    "\n",
    "print(f'RandForest train R2: {np.average(FST_train_R2)}')\n",
    "print(f'RandForest test R2: {np.average(FST_test_R2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ec555",
   "metadata": {},
   "source": [
    "## Miniscule improvements with Cluster information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95046eb",
   "metadata": {},
   "source": [
    "ü¶è Try **Full** Model by directly adding ZipCode Level information & feature select with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all columns except \n",
    "# PRICE, Sale_Type, Sold_Date, ADDRESS, CITY, State, px_perSF, HOA_perMonth, \n",
    "# Status, LATITUDE, LONGITUDE, LOCATION, Days_on_Mkt, AverageHouseValue\n",
    "unwanted = ['PRICE','Sale_Type', 'Sold_Date', 'ADDRESS', 'CITY', 'State', 'LOCATION',\n",
    "            'Days_on_Mkt', 'px_perSF', 'HOA_perMonth', 'STATUS', 'LATITUDE', 'LONGITUDE','AverageHouseValue']\n",
    "RF.drop(columns=unwanted).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae2675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_feats = ['Prop_Type','BEDS','BATHS','SF','Lot_Size','YearBuilt','zip']\n",
    "# target_feats = ['Prop_Type','BEDS','BATHS','SF','Lot_Size','YearBuilt','zip','cluster']\n",
    "target_feats = ['Prop_Type', 'BEDS', 'BATHS', 'SF', 'Lot_Size', 'YearBuilt', 'zip',\n",
    "        'Population', 'HouseholdsPerZipCode', 'MedianAge', 'NumberOfBusinesses', \n",
    "        'over_65_ratio', 'school_rating', 'Hosp_count', 'HPI', 'Demand_score', \n",
    "        'Supply_score', 'listviews_vs_US', 'med_days_on_mkt', 'nielson_rank', \n",
    "        'UE_rate', 'Zillow_HVF', 'BEA_percap_income', 'Blacks_ratio', \n",
    "        'Hispanics_ratio', 'Asians_ratio', 'Indians_ratio', 'Others_ratio', \n",
    "        'Male_ratio']\n",
    "\n",
    "lm = LinearRegression()\n",
    "cat = CatBoostRegressor(verbose=False)\n",
    "\n",
    "LM_train_R2 = []\n",
    "LM_test_R2 = []\n",
    "\n",
    "CAT_train_R2 = []\n",
    "CAT_test_R2 = []\n",
    "\n",
    "for i in range(5):\n",
    "    X_train_dum, X_test_dum, X_train_le, X_test_le, y_train, y_test = get_train_test(RF,target_feats)\n",
    "    lm.fit(X_train_dum, y_train)\n",
    "    LM_train_R2.append(lm.score(X_train_dum, y_train))\n",
    "    LM_test_R2.append(lm.score(X_test_dum, y_test))\n",
    "   \n",
    "    cat.fit(X_train_le, y_train)\n",
    "    CAT_train_R2.append(cat.score(X_train_le, y_train))\n",
    "    CAT_test_R2.append(cat.score(X_test_le, y_test))\n",
    "    print(i+1)\n",
    "\n",
    "print(f'Linear Model train R2: {np.average(LM_train_R2)}')\n",
    "print(f'Linear Model test R2: {np.average(LM_test_R2)}')\n",
    "print(f'CatBoost train R2: {np.average(CAT_train_R2)}')\n",
    "print(f'CatBoost Model test R2: {np.average(CAT_test_R2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d868f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "lasso.set_params(normalize=True, max_iter=10000, random_state=44)\n",
    "lasso.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0527f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try different alphas\n",
    "alphas = np.linspace(0.00001,0.0005,20)\n",
    "coefs_lasso = []\n",
    "R2_train = []\n",
    "R2_test = []\n",
    "\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(X_train_dum, y_train)\n",
    "    coefs_lasso.append(lasso.coef_)\n",
    "    R2_train.append(lasso.score(X_train_dum, y_train))\n",
    "    R2_test.append(lasso.score(X_test_dum, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70db24a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_lasso = pd.DataFrame(coefs_lasso, index = alphas, columns = X_train_dum.columns)\n",
    "R2_lasso = pd.DataFrame({'train': R2_train,'test':R2_test}, index = alphas)\n",
    "coefs_lasso.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d7d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,6))\n",
    "fig.suptitle('Lasso Regression results')\n",
    "\n",
    "for feat in coefs_lasso.columns:\n",
    "    ax1.plot(coefs_lasso.index, 10**coefs_lasso[feat]) \n",
    "ax1.set_xlabel(r'hyperparameter $\\lambda$')\n",
    "ax1.set_ylabel(r'slope values')\n",
    "#ax1.legend(loc=1)\n",
    "for each in R2_lasso.columns:\n",
    "    ax2.plot(R2_lasso.index, R2_lasso[each], label=each)\n",
    "ax2.set_xlabel(r'hyperparameter $\\lambda$')\n",
    "ax2.legend(loc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c4a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.DataFrame(cat.get_feature_importance(), index=X_train_le.columns, columns=['feat_importance'])\n",
    "feat_importances = feat_importances.sort_values(by='feat_importance', ascending=False)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(7, 7))\n",
    "sns.barplot(x='feat_importance', y=feat_importances.index, data=feat_importances, color=\"teal\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a71e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cat_scores = []\n",
    "\n",
    "for num in range(3,len(feat_importances.index)):\n",
    "    print(num)\n",
    "    X_train_new = X_train_le[[*feat_importances.index[:num]]]\n",
    "    X_test_new = X_test_le[[*feat_importances.index[:num]]]\n",
    "    cat.fit(X_train_new, y_train)\n",
    "    Cat_scores.append(cat.score(X_test_new, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db2e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Cat_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a24464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
