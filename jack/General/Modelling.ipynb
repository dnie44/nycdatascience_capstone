{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ffed2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "from helper_funcs import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "807d723b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----pulling Redfin data from Azure storage----\n",
      "----Done----\n",
      "----pulling schools data from Azure storage----\n",
      "----Done----\n",
      "----merging all data----\n",
      "----Done----\n",
      "Shape: (75360, 22)\n"
     ]
    }
   ],
   "source": [
    "RF = get_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "197fba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Linear Dataframe\n",
    "\n",
    "\n",
    "RF = linear[linear['Sale_Type'] == 'MLS Listing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ec9ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear(RF):\n",
    "    RF.drop(RF[RF.BEDS.isna() | RF.BATHS.isna()].index, inplace=True)\n",
    "    RF.loc[RF.overallRating.isna(),'overallRating'] = 5\n",
    "    ### Split data into train test split\n",
    "    #pd.set_option('display.max_rows', None)\n",
    "    zip_houses = RF.groupby('zip').agg('count')['PRICE'].to_dict()\n",
    "    RF['houses_perZIP'] = RF.zip.apply(lambda r: zip_houses[r])\n",
    "    RF = RF[RF.houses_perZIP>4]\n",
    "    # Use groupby to split the df into smaller dfs for each ZIP\n",
    "    groups = RF.groupby('zip')\n",
    "    dfs = [groups.get_group(x) for x in groups.groups]\n",
    "    # Use first df to initiate X_train, X_test, etc\n",
    "    for d in dfs[:1]:\n",
    "        feat = d[['Prop_Type','BEDS','BATHS','SF','Lot_Size','YearBuilt','zip']]\n",
    "        feat.zip = feat.zip.astype('object')\n",
    "        y = np.log10(d.PRICE)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(feat, y)\n",
    "\n",
    "    # train_test_split each df then stack together\n",
    "    for d in dfs[1:]:\n",
    "        feat = d[['Prop_Type','BEDS','BATHS','SF','Lot_Size','YearBuilt','zip']]\n",
    "        feat.zip = feat.zip.astype('object')\n",
    "        y = np.log10(d.PRICE)\n",
    "        X_trainpiece, X_testpiece, y_trainpiece, y_testpiece = train_test_split(feat, y, test_size=0.25)\n",
    "        X_train = X_train.append(X_trainpiece)\n",
    "        X_test = X_test.append(X_testpiece)\n",
    "        y_train = y_train.append(y_trainpiece)\n",
    "        y_test = y_test.append(y_testpiece)\n",
    "        \n",
    "    X_train_linear = pd.get_dummies(X_train, drop_first=True)\n",
    "    X_test_linear = pd.get_dummies(X_test, drop_first=True)\n",
    "    return X_train_linear, X_test_linear, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b760cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree(RF):\n",
    "    RF.drop(RF[RF.BEDS.isna() | RF.BATHS.isna()].index, inplace=True)\n",
    "    RF.loc[RF.overallRating.isna(),'overallRating'] = 5\n",
    "    ### Split data into train test split\n",
    "    #pd.set_option('display.max_rows', None)\n",
    "    zip_houses = RF.groupby('zip').agg('count')['PRICE'].to_dict()\n",
    "    RF['houses_perZIP'] = RF.zip.apply(lambda r: zip_houses[r])\n",
    "    RF = RF[RF.houses_perZIP>4]\n",
    "    # Use groupby to split the df into smaller dfs for each ZIP\n",
    "    groups = RF.groupby('zip')\n",
    "    dfs = [groups.get_group(x) for x in groups.groups]\n",
    "    # Use first df to initiate X_train, X_test, etc\n",
    "    for d in dfs[:1]:\n",
    "        feat = d[['Prop_Type','BEDS','BATHS','SF','Lot_Size','YearBuilt','zip']]\n",
    "        feat.zip = feat.zip.astype('object')\n",
    "        y = np.log10(d.PRICE)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(feat, y)\n",
    "\n",
    "    # train_test_split each df then stack together\n",
    "    for d in dfs[1:]:\n",
    "        feat = d[['Prop_Type','BEDS','BATHS','SF','Lot_Size','YearBuilt','zip']]\n",
    "        feat.zip = feat.zip.astype('object')\n",
    "        y = np.log10(d.PRICE)\n",
    "        X_trainpiece, X_testpiece, y_trainpiece, y_testpiece = train_test_split(feat, y, test_size=0.25)\n",
    "        X_train = X_train.append(X_trainpiece)\n",
    "        X_test = X_test.append(X_testpiece)\n",
    "        y_train = y_train.append(y_trainpiece)\n",
    "        y_test = y_test.append(y_testpiece)\n",
    "\n",
    "    X_train_le = X_train.copy()\n",
    "    X_test_le = X_test.copy()\n",
    "    le = LabelEncoder()\n",
    "    X_train_le.Prop_Type = le.fit_transform(X_train_le.Prop_Type)\n",
    "    X_test_le.Prop_Type = le.fit_transform(X_test_le.Prop_Type)\n",
    "    return X_train_le, X_test_le, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0f6a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_linear, X_test_linear, y_train, y_test = get_linear(RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50b09857",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tree, X_test_tree, y_train, y_test = get_tree(RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da4bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing out Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "542fded9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train R2: 0.40657685038589264\n",
      "train R2: 0.3591230416941972\n"
     ]
    }
   ],
   "source": [
    "### Linear Regression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_linear, y_train)\n",
    "print(f'train R2: {lm.score(X_train_linear, y_train)}')\n",
    "print(f'train R2: {lm.score(X_test_linear, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70b18d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2: 0.8246070251399195\n",
      "Test R2: 0.7958135932320387\n"
     ]
    }
   ],
   "source": [
    "## CatBoost\n",
    "\n",
    "cat = CatBoostRegressor(verbose=False)\n",
    "cat.get_params()\n",
    "cat.fit(X_train_tree, y_train)\n",
    "print(f'Train R2: {cat.score(X_train_tree, y_train)}')\n",
    "print(f'Test R2: {cat.score(X_test_tree, y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
